{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convert_models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlYdIM2rWHmJ"
      },
      "source": [
        "## Import all of used library \n",
        "is needed to run all of the cells in this section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG8CKMi7WPSG"
      },
      "source": [
        "# To remove all warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import requests\n",
        "import random\n",
        "import calendar\n",
        "import time\n",
        "import pickle\n",
        "import tempfile\n",
        "import joblib\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from shutil import move\n",
        "from shutil import copy\n",
        "from shutil import make_archive\n",
        "from shutil import rmtree\n",
        "\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.applications import MobileNet, MobileNetV2, VGG16, EfficientNetB0, InceptionV3, \\\n",
        "                                           VGG19, Xception, DenseNet121, DenseNet201, ResNet152V2, EfficientNetB5\n",
        "from tensorflow.keras.layers import Input, AveragePooling2D, Dense, Dropout, Flatten\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy, BinaryCrossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.utils import get_file\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow import lite, cast, float32, saved_model, keras\n",
        "from tensorflow.python.keras.layers import deserialize, serialize\n",
        "from tensorflow.python.keras.saving import saving_utils\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1xaIW1kW29G"
      },
      "source": [
        "# To mounting Google Drive\n",
        "\n",
        "def google_drive_mount(mounting=False):\n",
        "  if mounting:\n",
        "    drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDXnTB3bzy4e"
      },
      "source": [
        "# Download the file\n",
        "\n",
        "def download_file(urls, unzip=True, remove_after_unzip=False, google_drive=False, filename='tmp', ext='zip'):\n",
        "\n",
        "  url = urls\n",
        "  CHUNK_SIZE = 32768\n",
        "  file_tmp = f'{filename}.{ext}'\n",
        "\n",
        "  # If Downloading from Google Drive\n",
        "  if google_drive:\n",
        "\n",
        "    # Get the token\n",
        "    def get_confirm_token(response):\n",
        "      \n",
        "      for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "          return value\n",
        "      return None\n",
        "    \n",
        "    url_raw = 'https://docs.google.com/uc?export=download'\n",
        "    file_id = url.split('/')[-2] # Split the file id\n",
        "    session = requests.Session() # Get session\n",
        "    response = session.get(url_raw, params={'id': file_id}, stream=True) # Get the response\n",
        "    token = get_confirm_token(response) # Get the token\n",
        "\n",
        "    # If there is token\n",
        "    if token:\n",
        "      response = session.get(url_raw, params={'id': file_id, 'confirm': token}, stream=True) # Get the response\n",
        "    \n",
        "    # Save the response as zip file\n",
        "    with open(f'{os.getcwd()}/{file_tmp}', 'wb') as f:\n",
        "      for chunk in response.iter_content(CHUNK_SIZE):\n",
        "        if chunk:\n",
        "          f.write(chunk)\n",
        "  \n",
        "  # If not from Google Drive\n",
        "  else:\n",
        "    filedata = get_file(origin=url, fname=os.path.join(os.getcwd(), file_tmp)) # Get the response from URL\n",
        "\n",
        "  # Extract the zip files\n",
        "  if unzip:\n",
        "    local_zip = f'{os.getcwd()}/{file_tmp}'\n",
        "    zip_ref = zipfile.ZipFile(local_zip, 'r') # Extract \n",
        "    zip_ref.extractall(f'{os.getcwd()}/') # Extract\n",
        "    zip_ref.close()\n",
        "    # Remove the zip file after unzip\n",
        "    if remove_after_unzip:\n",
        "      os.remove(f'{os.getcwd()}/{file_tmp}')  \n",
        "  \n",
        "  # If not a zip file\n",
        "  else:\n",
        "    return f'{os.getcwd()}/{file_tmp}'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hmooW6WBfFB"
      },
      "source": [
        "# Load the saved models/checkpoints models from Google Drive\n",
        "\n",
        "def load_models(url, summary=False, filenames='tmp'):\n",
        "  model_download = download_file(url, unzip=False, remove_after_unzip=True, google_drive=True, ext=\"h5\", filename=filenames)  \n",
        "  model = load_model(model_download)\n",
        "  if summary:\n",
        "    model.summary()\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o52Wz27RSBk_"
      },
      "source": [
        "links = 'https://drive.google.com/file/d/1-0ODyEWBJcERmvXXM5Ejk_VoxV7gI6SW/view?usp=sharing'\n",
        "model = load_models(links)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPKBN771L7ha"
      },
      "source": [
        "# Convert Keras Model to Tensorflow SavedModel\n",
        "Purposed in this section to convert checkpoint model (keras *.h5 format) to SavedModel Tensorflow format, in order you want to deploy it to web or Google Cloud or something that needed Tensorflow SavedModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2lMmVYIXStr"
      },
      "source": [
        "# Load the saved models/checkpoints models from Google Drive\n",
        "\n",
        "def KerastoSavedModel(links, path='/content/drive/MyDrive/', \n",
        "                      make_zip=False, move_to_drive=True, name='models', \n",
        "                      ext='zip', raw_model=False):\n",
        "\n",
        "    # Load model from Keras\n",
        "    def load_models(url, summary=False, filenames='tmp'):    \n",
        "        model_download = download_file(url, unzip=False, remove_after_unzip=True, google_drive=True, ext=\"h5\", filename=filenames)  \n",
        "        model = load_model(model_download)    \n",
        "        if summary:\n",
        "            model.summary()\n",
        "        return model\n",
        "    model = load_models(links)\n",
        "\n",
        "    # Convert it to SavedModel\n",
        "    saved_model.save(model, f'{os.getcwd()}/{name}')\n",
        "\n",
        "    # Store it on zip files\n",
        "    if make_zip:\n",
        "        make_archive(name, ext, f'{os.getcwd()}/{name}') # Create the new zip file\n",
        "    \n",
        "    # Move it to drive\n",
        "    if move_to_drive:\n",
        "        google_drive_mount(mounting=True) # Mount Google Drive\n",
        "        \n",
        "        if not os.path.exists(path):\n",
        "            os.mkdir(path)\n",
        "\n",
        "        copy(f'{os.getcwd()}/{name}.{ext}', path) # Move zip file to Google Drive\n",
        "        print(f'Saved model zip to {path}')\n",
        "        \n",
        "        if raw_model: # Move raw model to Google Drive\n",
        "            copy(f'{os.getcwd()}/{name}', path)\n",
        "            print(f'Saved model raw to {path}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9trDRDhrL7Ni",
        "outputId": "947f1784-907e-4375-87e5-337973e285c3"
      },
      "source": [
        "links = 'https://drive.google.com/file/d/1-0ODyEWBJcERmvXXM5Ejk_VoxV7gI6SW/view?usp=sharing'\n",
        "\n",
        "KerastoSavedModel(links, make_zip=True, move_to_drive=True, raw_model=True, name='test_model',\n",
        "                  path='/content/drive/MyDrive/fix-datasets-new/test')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
            "INFO:tensorflow:Assets written to: /content/test_model/assets\n",
            "Mounted at /content/drive\n",
            "Saved model zip to /content/drive/MyDrive/fix-datasets-new/test\n",
            "Saved model raw to /content/drive/MyDrive/fix-datasets-new/test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-tEN6yRpFEk"
      },
      "source": [
        "# Convert to TFLite\n",
        "Purposed in this section to convert checkpoint model (keras *.h5 format) to Tensorflow lite format, in order you want to deploy it to web, embedded, mobile or microcontroller devices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95_xWYcW5Lok"
      },
      "source": [
        "def to_tflite(links, tflite_filename='converted_model', optimizations='size',\n",
        "              move_to_drive=False, path='/content/drive/MyDrive/'):\n",
        "    \n",
        "    # Load model from Keras\n",
        "    def load_models(url, summary=False, filenames='tmp'):    \n",
        "        model_download = download_file(url, unzip=False, remove_after_unzip=True, google_drive=True, ext=\"h5\", filename=filenames)  \n",
        "        model = load_model(model_download)    \n",
        "        if summary:\n",
        "            model.summary()\n",
        "        return model\n",
        "    model = load_models(links)\n",
        "    \n",
        "    converter = lite.TFLiteConverter.from_keras_model(model)\n",
        "    \n",
        "    if optimizations in ['size', 'SIZE']:\n",
        "        converter.optimizations = [lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "    \n",
        "    if optimizations in ['latency', 'LATENCY']:\n",
        "        converter.optimizations = [lite.Optimize.OPTIMIZE_FOR_LATENCY]\n",
        "    \n",
        "    tflite_model = converter.convert()\n",
        "    \n",
        "    with open(f'{os.getcwd()}/{tflite_filename}.tflite', 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "\n",
        "    if move_to_drive:\n",
        "        google_drive_mount(mounting=True) # Mount Google Drive\n",
        "        \n",
        "        if not os.path.exists(path):\n",
        "            os.mkdir(path)\n",
        "\n",
        "        copy(f'{os.getcwd()}/{tflite_filename}.tflite', path) # Move zip file to Google Drive\n",
        "        print(f'Saved tflite to {path}')\n",
        "    \n",
        "    return f'{tflite_filename}.tflite'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDlhGsD01HNH",
        "outputId": "bd3d6417-0cd3-4f0d-fe0d-f5740e325df7"
      },
      "source": [
        "links = 'https://drive.google.com/file/d/1-0ODyEWBJcERmvXXM5Ejk_VoxV7gI6SW/view?usp=sharing' # Load Keras Models or SavedModel\n",
        "\n",
        "tflite_filename = to_tflite(links, move_to_drive=True, tflite_filename='test',\n",
        "                            path='/content/drive/MyDrive/fix-datasets-new/test')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpe_9j8atz/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpe_9j8atz/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Saved tflite to /content/drive/MyDrive/fix-datasets-new/test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Viqj7Vk44cAe"
      },
      "source": [
        "# Pickle the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pt-yny1LByhN"
      },
      "source": [
        "# Load the saved models/checkpoints models from Google Drive\n",
        "\n",
        "def load_models(url, summary=False, filenames='tmp'):\n",
        "    \n",
        "    model_download = download_file(url, unzip=False, remove_after_unzip=True, google_drive=True, ext=\"h5\", filename=filenames)  \n",
        "    \n",
        "    model = load_model(model_download)\n",
        "    \n",
        "    if summary:\n",
        "        model.summary()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6mBoyNM4bbe"
      },
      "source": [
        "links = 'https://drive.google.com/file/d/1-0ODyEWBJcERmvXXM5Ejk_VoxV7gI6SW/view?usp=sharing'\n",
        "model = load_models(links)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2CMeB2K4hIO"
      },
      "source": [
        "def unpack(model, training_config, weights):\n",
        "    restored_model = deserialize(model)\n",
        "    if training_config is not None:\n",
        "        restored_model.compile(\n",
        "            **saving_utils.compile_args_from_training_config(\n",
        "                training_config\n",
        "            )\n",
        "        )\n",
        "    restored_model.set_weights(weights)\n",
        "    return restored_model\n",
        "\n",
        "# Hotfix function\n",
        "def make_keras_picklable():\n",
        "    def __reduce__(self):\n",
        "        model_metadata = saving_utils.model_metadata(self)\n",
        "        training_config = model_metadata.get(\"training_config\", None)\n",
        "        model = serialize(self)\n",
        "        weights = self.get_weights()\n",
        "        return (unpack, (model, training_config, weights))\n",
        "    cls = keras.Model\n",
        "    cls.__reduce__ = __reduce__\n",
        "\n",
        "# Source: https://github.com/tensorflow/tensorflow/issues/34697"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDizk6eb7ivm"
      },
      "source": [
        "def convert_pickle(model, model_name='model', ext='pkl', save_to_drive=False,\n",
        "                   path_to_drive='/content/drive/MyDrive/fix-datasets/saved_model'):\n",
        "    \n",
        "    make_keras_picklable() # Call picklabel function\n",
        "    \n",
        "    if ext is 'pkl':\n",
        "        with open(f'{model_name}.{ext}', 'wb') as f:\n",
        "            pickle.dump(model, f)\n",
        "        print(f'Converting {model_name}.{ext} succesfully')\n",
        "    \n",
        "    if ext is 'joblib':\n",
        "        with open(f'{model_name}.{ext}', 'wb') as f:\n",
        "            joblib.dump(model, f)\n",
        "        print(f'Converting {model_name}.{ext} succesfully')\n",
        "    \n",
        "    if save_to_drive:\n",
        "        google_drive_mount(mounting=True) \n",
        "        copy(f'{model_name}.{ext}', path_to_drive) "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxuUT22R-Ev2",
        "outputId": "c757c7be-2456-4317-a043-1f606292c171"
      },
      "source": [
        "convert_pickle(model)\n",
        "convert_pickle(model, ext='joblib')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Converting model.pkl succesfully\n",
            "Converting model.joblib succesfully\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}